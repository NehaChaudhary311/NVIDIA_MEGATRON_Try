{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Megatron-Try2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfUblSfi43722JmEZi5i6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaChaudhary311/NVIDIA_MEGATRON_Try/blob/master/Megatron_Try2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJXIHOZvk9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "97161e8f-24d4-468f-dbd7-f1c63bc547dd"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/Megatron-LM.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Megatron-LM'...\n",
            "remote: Enumerating objects: 1085, done.\u001b[K\n",
            "remote: Counting objects: 100% (1085/1085), done.\u001b[K\n",
            "remote: Compressing objects: 100% (388/388), done.\u001b[K\n",
            "remote: Total 1357 (delta 723), reused 1032 (delta 694), pack-reused 272\u001b[K\n",
            "Receiving objects: 100% (1357/1357), 628.45 KiB | 11.03 MiB/s, done.\n",
            "Resolving deltas: 100% (872/872), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHsBHZ_uwQGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5729e924-45d3-4fc7-bd6c-436e31f9c546"
      },
      "source": [
        "!pwd\n",
        "!cd Megatron-LM"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkMHDvWX5olO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a103953-832f-4679-9745-ce643e768da5"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlTe7hMM5rNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "331c3720-8a09-49f1-8f9f-68373ebdca8d"
      },
      "source": [
        "cd Megatron-LM/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Megatron-LM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEM1Umkg5t4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "be82b4b4-fe42-4788-8de5-b6b922ffffab"
      },
      "source": [
        "!python pretrain_bert.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"pretrain_bert.py\", line 23, in <module>\n",
            "    from megatron import mpu\n",
            "  File \"/content/Megatron-LM/megatron/mpu/__init__.py\", line 22, in <module>\n",
            "    from .grads import clip_grad_norm\n",
            "  File \"/content/Megatron-LM/megatron/mpu/grads.py\", line 24, in <module>\n",
            "    from apex.multi_tensor_apply import multi_tensor_applier\n",
            "ModuleNotFoundError: No module named 'apex'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsOpnRc6NRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3f37e550-990d-4c12-84a5-c5e011a7f17a"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)\u001b[K\rremote: Compressing objects:  28% (2/7)\u001b[K\rremote: Compressing objects:  42% (3/7)\u001b[K\rremote: Compressing objects:  57% (4/7)\u001b[K\rremote: Compressing objects:  71% (5/7)\u001b[K\rremote: Compressing objects:  85% (6/7)\u001b[K\rremote: Compressing objects: 100% (7/7)\u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "Receiving objects:   0% (1/6749)   \rReceiving objects:   1% (68/6749)   \rReceiving objects:   2% (135/6749)   \rReceiving objects:   3% (203/6749)   \rReceiving objects:   4% (270/6749)   \rReceiving objects:   5% (338/6749)   \rReceiving objects:   6% (405/6749)   \rReceiving objects:   7% (473/6749)   \rReceiving objects:   8% (540/6749)   \rReceiving objects:   9% (608/6749)   \rReceiving objects:  10% (675/6749)   \rReceiving objects:  11% (743/6749)   \rReceiving objects:  12% (810/6749)   \rReceiving objects:  13% (878/6749)   \rReceiving objects:  14% (945/6749)   \rReceiving objects:  15% (1013/6749)   \rReceiving objects:  16% (1080/6749)   \rReceiving objects:  17% (1148/6749)   \rReceiving objects:  18% (1215/6749)   \rReceiving objects:  19% (1283/6749)   \rReceiving objects:  20% (1350/6749)   \rReceiving objects:  21% (1418/6749)   \rReceiving objects:  22% (1485/6749)   \rReceiving objects:  23% (1553/6749)   \rReceiving objects:  24% (1620/6749)   \rReceiving objects:  25% (1688/6749)   \rReceiving objects:  26% (1755/6749)   \rReceiving objects:  27% (1823/6749)   \rReceiving objects:  28% (1890/6749)   \rReceiving objects:  29% (1958/6749)   \rReceiving objects:  30% (2025/6749)   \rReceiving objects:  31% (2093/6749)   \rReceiving objects:  32% (2160/6749)   \rReceiving objects:  33% (2228/6749)   \rReceiving objects:  34% (2295/6749)   \rReceiving objects:  35% (2363/6749)   \rReceiving objects:  36% (2430/6749)   \rReceiving objects:  37% (2498/6749)   \rReceiving objects:  38% (2565/6749)   \rReceiving objects:  39% (2633/6749)   \rReceiving objects:  40% (2700/6749)   \rReceiving objects:  41% (2768/6749)   \rReceiving objects:  42% (2835/6749)   \rReceiving objects:  43% (2903/6749)   \rReceiving objects:  44% (2970/6749)   \rReceiving objects:  45% (3038/6749)   \rReceiving objects:  46% (3105/6749)   \rReceiving objects:  47% (3173/6749)   \rReceiving objects:  48% (3240/6749)   \rReceiving objects:  49% (3308/6749)   \rReceiving objects:  50% (3375/6749)   \rReceiving objects:  51% (3442/6749)   \rReceiving objects:  52% (3510/6749)   \rReceiving objects:  53% (3577/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  54% (3645/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  55% (3712/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  56% (3780/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  57% (3847/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  58% (3915/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  59% (3982/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  60% (4050/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  61% (4117/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  62% (4185/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  63% (4252/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  64% (4320/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  65% (4387/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  66% (4455/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  67% (4522/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  68% (4590/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  69% (4657/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  70% (4725/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  71% (4792/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  72% (4860/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  73% (4927/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  74% (4995/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  75% (5062/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  76% (5130/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  77% (5197/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  78% (5265/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  79% (5332/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  80% (5400/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  81% (5467/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  82% (5535/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  83% (5602/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  84% (5670/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  85% (5737/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  86% (5805/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  87% (5872/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  88% (5940/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  89% (6007/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  90% (6075/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  91% (6142/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  92% (6210/6749), 12.75 MiB | 25.50 MiB/s   \rReceiving objects:  93% (6277/6749), 12.75 MiB | 25.50 MiB/s   \rremote: Total 6749 (delta 0), reused 1 (delta 0), pack-reused 6742\u001b[K\n",
            "Receiving objects: 100% (6749/6749), 13.74 MiB | 25.63 MiB/s, done.\n",
            "Resolving deltas: 100% (4507/4507), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEKIcptz6VTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "05760a81-3a3a-47a6-c79d-d3d7b4026fe5"
      },
      "source": [
        "!python pretrain_bert.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"pretrain_bert.py\", line 23, in <module>\n",
            "    from megatron import mpu\n",
            "  File \"/content/Megatron-LM/megatron/mpu/__init__.py\", line 22, in <module>\n",
            "    from .grads import clip_grad_norm\n",
            "  File \"/content/Megatron-LM/megatron/mpu/grads.py\", line 24, in <module>\n",
            "    from apex.multi_tensor_apply import multi_tensor_applier\n",
            "ModuleNotFoundError: No module named 'apex.multi_tensor_apply'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuQ-3M16zeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eabc3b33-9ad6-499a-ccb0-24b332ee218b"
      },
      "source": [
        "cd megatron/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Megatron-LM/megatron\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_6C4xs7Fm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python module.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiYY9_S7O-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1beb5f0-4e1f-4b81-93c5-695c3be1a023"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Megatron-LM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VWdxJ-w7YSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "27a00e8d-6de1-425e-e6a6-25fc60383507"
      },
      "source": [
        "!python pretrain_gpt2.py"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"pretrain_gpt2.py\", line 23, in <module>\n",
            "    from megatron import mpu\n",
            "  File \"/content/Megatron-LM/megatron/mpu/__init__.py\", line 22, in <module>\n",
            "    from .grads import clip_grad_norm\n",
            "  File \"/content/Megatron-LM/megatron/mpu/grads.py\", line 24, in <module>\n",
            "    from apex.multi_tensor_apply import multi_tensor_applier\n",
            "ModuleNotFoundError: No module named 'apex.multi_tensor_apply'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}